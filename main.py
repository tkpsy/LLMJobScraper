import json
import sys
import time
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime

from src.scrapers.html_scraper import HTMLScraper
from src.processors.job_extractor import JobExtractor
from src.processors.job_matcher import JobMatcher
from src.models.user_profile import UserProfile
from src.utils.config import (
    SCRAPING_CONFIG, MATCHING_CONFIG, 
    USER_PROFILE_CONFIG, EXECUTION_CONFIG, OUTPUT_CONFIG, LLM_CATEGORY_SELECTION_CONFIG
)
from api import generate_chat_completion

class CrowdWorksCategoryExplorer:
    """ã‚«ãƒ†ã‚´ãƒªãƒ™ãƒ¼ã‚¹ã®CrowdWorksæ¡ˆä»¶æ¢ç´¢ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.html_scraper = HTMLScraper()
        self.job_extractor = JobExtractor()
        self.job_matcher = JobMatcher()
        self.categories_file = Path("categories.json")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­ã«ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½è·¡
        self.saved_files = {
            'html_files': [],
            'job_files': [],
            'match_files': [],
            'screenshot_files': []
        }
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        self.user_profile = UserProfile(
            skills=USER_PROFILE_CONFIG["skills"],
            preferred_categories=USER_PROFILE_CONFIG["preferred_categories"],
            preferred_work_type=USER_PROFILE_CONFIG["preferred_work_type"],
            description=USER_PROFILE_CONFIG["description"]
        )
    
    def load_categories(self) -> Dict:
        """ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã‚’èª­ã¿è¾¼ã‚€"""
        if not self.categories_file.exists():
            print("ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã¾ãšã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚")
            return {}
        
        with open(self.categories_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def find_category_by_name(self, categories: Dict, main_category_name: str, subcategory_name: Optional[str] = None) -> Optional[Dict]:
        """ã‚«ãƒ†ã‚´ãƒªåã‹ã‚‰è©²å½“ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’æ¤œç´¢"""
        for category in categories.get("main_categories", []):
            if category["name"] == main_category_name:
                if subcategory_name is None:
                    return category
                else:
                    # ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªã‚’æ¤œç´¢
                    for subcategory in category.get("subcategories", []):
                        if subcategory["name"] == subcategory_name:
                            return subcategory
        return None
    
    def scrape_category_jobs(self, category_url: str) -> List[Path]:
        """æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã®æ¡ˆä»¶ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"""
        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°è¨­å®šã‚’æ›´æ–°
        original_url = SCRAPING_CONFIG["base_url"]
        SCRAPING_CONFIG["base_url"] = category_url
        
        try:
            if OUTPUT_CONFIG["console_output"]:
                print(f"ã‚«ãƒ†ã‚´ãƒªãƒšãƒ¼ã‚¸ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ä¸­: {category_url}")
            
            # è¤‡æ•°ãƒšãƒ¼ã‚¸å¯¾å¿œã®ãƒã‚§ãƒƒã‚¯
            max_pages = EXECUTION_CONFIG.get("max_pages_per_category", 1)
            if max_pages > 1:
                # è¤‡æ•°ãƒšãƒ¼ã‚¸ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
                html_files = self.html_scraper.save_html_with_pagination(
                    category_url=category_url, 
                    max_pages=max_pages
                )
            else:
                # å¾“æ¥ã®å˜ä¸€ãƒšãƒ¼ã‚¸ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
                html_file = self.html_scraper.save_html_single()
                html_files = [html_file]
            
            # ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¨˜éŒ²
            self.saved_files['html_files'].extend(html_files)
            
            # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚‚è¨˜éŒ²
            if EXECUTION_CONFIG["save_screenshots"]:
                for html_file in html_files:
                    timestamp = html_file.stem.replace('page_', '')
                    screenshot_file = html_file.parent / f'screenshot_{timestamp}.png'
                    if screenshot_file.exists():
                        self.saved_files['screenshot_files'].append(screenshot_file)
            
            return html_files
        
        except Exception as e:
            print(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return []
        
        finally:
            # è¨­å®šã‚’å…ƒã«æˆ»ã™
            SCRAPING_CONFIG["base_url"] = original_url
    
    def extract_jobs_only(self, html_files: List[Path]) -> List:
        """HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ¡ˆä»¶ã‚’æŠ½å‡ºã™ã‚‹ã®ã¿ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ãªã—ï¼‰"""
        if OUTPUT_CONFIG["console_output"]:
            print("æ¡ˆä»¶æƒ…å ±ã‚’æŠ½å‡ºä¸­...")
        
        all_jobs = []
        
        # è¤‡æ•°ã®HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ¡ˆä»¶ã‚’æŠ½å‡º
        for i, html_file in enumerate(html_files, 1):
            if OUTPUT_CONFIG["console_output"]:
                print(f"  ãƒ•ã‚¡ã‚¤ãƒ« {i}/{len(html_files)}: {html_file.name}")
            
            jobs = self.job_extractor.extract_jobs(html_file)
            all_jobs.extend(jobs)
            
            if OUTPUT_CONFIG["console_output"]:
                print(f"    æŠ½å‡ºä»¶æ•°: {len(jobs)}ä»¶")
        
        # é‡è¤‡æ¡ˆä»¶ã®é™¤å»
        unique_jobs = self._remove_duplicate_jobs(all_jobs)
        
        if OUTPUT_CONFIG["console_output"]:
            print(f"åˆè¨ˆæŠ½å‡ºä»¶æ•°: {len(all_jobs)}ä»¶")
            print(f"é‡è¤‡é™¤å»å¾Œ: {len(unique_jobs)}ä»¶")
        
        return unique_jobs
    
    def match_jobs_only(self, jobs: List) -> List:
        """æ¡ˆä»¶ã®ãƒãƒƒãƒãƒ³ã‚°è©•ä¾¡ã®ã¿ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ãªã—ï¼‰"""
        if not jobs:
            if OUTPUT_CONFIG["console_output"]:
                print("æ¡ˆä»¶ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return []
        
        if OUTPUT_CONFIG["console_output"]:
            print("æ¡ˆä»¶ã®ãƒãƒƒãƒãƒ³ã‚°è©•ä¾¡ã‚’å®Ÿè¡Œä¸­...")
        
        # ä¸€æ™‚çš„ã«æ¡ˆä»¶ã‚’è¨­å®šã—ã¦ãƒãƒƒãƒãƒ³ã‚°å®Ÿè¡Œ
        self.job_matcher.jobs = jobs
        matches = self.job_matcher.find_matching_jobs(
            user_profile=self.user_profile,
            min_score=MATCHING_CONFIG["min_score"],
            max_jobs=MATCHING_CONFIG["max_jobs"]
        )
        
        return matches
    
    def save_all_jobs_and_matches(self, all_jobs: List, all_matches: List) -> None:
        """å…¨ã‚«ãƒ†ã‚´ãƒªã®æ¡ˆä»¶ã¨ãƒãƒƒãƒãƒ³ã‚°çµæœã‚’çµ±åˆã—ã¦ä¿å­˜"""
        if OUTPUT_CONFIG["console_output"]:
            print(f"\nğŸ“Š å…¨ã‚«ãƒ†ã‚´ãƒªã®æ¡ˆä»¶ã‚’çµ±åˆä¿å­˜ä¸­...")
            print(f"   ç·æ¡ˆä»¶æ•°: {len(all_jobs)}ä»¶")
            print(f"   ãƒãƒƒãƒãƒ³ã‚°çµæœ: {len(all_matches)}ä»¶")
        
        # å…¨æ¡ˆä»¶ã‚’JSONã§ä¿å­˜
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        job_file = self.job_extractor.save_jobs_to_json(all_jobs, timestamp)
        self.saved_files['job_files'].append(job_file)
        
        # å…¨ãƒãƒƒãƒãƒ³ã‚°çµæœã‚’ä¿å­˜
        if all_matches:
            try:
                matching_result_file = self.job_matcher.save_matching_results(all_matches, self.user_profile)
                self.saved_files['match_files'].append(matching_result_file)
                
                if OUTPUT_CONFIG["console_output"]:
                    print(f"âœ… å…¨æ¡ˆä»¶ã‚’ {job_file} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
                    print(f"âœ… å…¨ãƒãƒƒãƒãƒ³ã‚°çµæœã‚’ {matching_result_file} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
                    
            except Exception as e:
                if OUTPUT_CONFIG["console_output"]:
                    print(f"ãƒãƒƒãƒãƒ³ã‚°çµæœã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        
        # ãƒãƒƒãƒãƒ³ã‚°çµæœã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¨˜éŒ²
        match_files = list(Path("data/matches").glob("all_evaluations_*.csv"))
        if match_files:
            latest_match_file = max(match_files, key=lambda x: x.stat().st_mtime)
            if latest_match_file not in self.saved_files['match_files']:
                self.saved_files['match_files'].append(latest_match_file)
    
    def _remove_duplicate_jobs(self, jobs: List) -> List:
        """é‡è¤‡æ¡ˆä»¶ã‚’é™¤å»ã™ã‚‹"""
        unique_jobs = []
        seen_titles = set()
        
        for job in jobs:
            # ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåã®çµ„ã¿åˆã‚ã›ã§é‡è¤‡ãƒã‚§ãƒƒã‚¯
            job_key = (job.title, job.client_name)
            if job_key not in seen_titles:
                seen_titles.add(job_key)
                unique_jobs.append(job)
        
        return unique_jobs
    
    def display_matches(self, matches: List) -> None:
        """ãƒãƒƒãƒãƒ³ã‚°çµæœã‚’è¡¨ç¤º"""
        if not OUTPUT_CONFIG["console_output"]:
            return
            
        if not matches:
            print("\næ¡ä»¶ã«åˆã†æ¡ˆä»¶ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return
        
        print(f"\næ¨è–¦æ¡ˆä»¶ ({len(matches)}ä»¶):")
        print("=" * 60)
        
        for i, match in enumerate(matches, 1):
            job = match.job
            print(f"\n{i}. {job['title']}")
            print(f"   é–¢é€£åº¦ã‚¹ã‚³ã‚¢: {match.relevance_score:.1f}/100")
            print(f"   ã‚«ãƒ†ã‚´ãƒª: {job.get('category', 'æœªåˆ†é¡')}")
            print(f"   ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ: {job.get('client_name', 'ä¸æ˜')}")
            
            if job.get('budget'):
                budget = job['budget']
                if budget.get('min_amount') and budget.get('max_amount'):
                    print(f"   äºˆç®—: {budget['min_amount']:,}å†† ï½ {budget['max_amount']:,}å†† ({budget['type']})")
                elif budget.get('min_amount'):
                    print(f"   äºˆç®—: {budget['min_amount']:,}å†† ({budget['type']})")
                else:
                    print(f"   äºˆç®—: ç›¸è«‡ ({budget['type']})")
            
            if job.get('deadline'):
                print(f"   æœŸé™: {job['deadline']}")
            
            if job.get('url'):
                print(f"   URL: {job['url']}")
            
            # èª¬æ˜æ–‡ã®ä¸€éƒ¨ã‚’è¡¨ç¤º
            description = job.get('description', '')
            if description:
                desc_preview = description[:100] + "..." if len(description) > 100 else description
                print(f"   èª¬æ˜: {desc_preview}")
            
            print("-" * 60)
    
    def display_saved_files_summary(self) -> None:
        """ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±ã‚’è¡¨ç¤º"""
        if not OUTPUT_CONFIG["detailed_summary"]:
            return
            
        print("\n" + "=" * 60)
        print("ğŸ—‚ï¸  ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­ã«ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§")
        print("=" * 60)
        
        total_files = 0
        
        if self.saved_files['html_files']:
            print(f"\nğŸ“„ HTMLãƒ•ã‚¡ã‚¤ãƒ« ({len(self.saved_files['html_files'])}ä»¶):")
            for file_path in self.saved_files['html_files']:
                if OUTPUT_CONFIG["show_file_sizes"]:
                    file_size = file_path.stat().st_size / 1024  # KB
                    print(f"   - {file_path} ({file_size:.1f}KB)")
                else:
                    print(f"   - {file_path}")
                total_files += 1
        
        if self.saved_files['screenshot_files']:
            print(f"\nğŸ“¸ ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ ({len(self.saved_files['screenshot_files'])}ä»¶):")
            for file_path in self.saved_files['screenshot_files']:
                if OUTPUT_CONFIG["show_file_sizes"]:
                    file_size = file_path.stat().st_size / 1024  # KB
                    print(f"   - {file_path} ({file_size:.1f}KB)")
                else:
                    print(f"   - {file_path}")
                total_files += 1
        
        if self.saved_files['job_files']:
            print(f"\nğŸ“‹ æ¡ˆä»¶ãƒ‡ãƒ¼ã‚¿ (JSON) ({len(self.saved_files['job_files'])}ä»¶):")
            for file_path in self.saved_files['job_files']:
                if OUTPUT_CONFIG["show_file_sizes"]:
                    file_size = file_path.stat().st_size / 1024  # KB
                    print(f"   - {file_path} ({file_size:.1f}KB)")
                else:
                    print(f"   - {file_path}")
                total_files += 1
        
        if self.saved_files['match_files']:
            print(f"\nğŸ“Š ãƒãƒƒãƒãƒ³ã‚°çµæœ (CSV) ({len(self.saved_files['match_files'])}ä»¶):")
            for file_path in self.saved_files['match_files']:
                if OUTPUT_CONFIG["show_file_sizes"]:
                    file_size = file_path.stat().st_size / 1024  # KB
                    print(f"   - {file_path} ({file_size:.1f}KB)")
                else:
                    print(f"   - {file_path}")
                total_files += 1
        
        if total_files == 0:
            print("\nâš ï¸  ã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            print(f"\nâœ… åˆè¨ˆ {total_files} ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
        
        print("\nğŸ’¡ ãƒ’ãƒ³ãƒˆ:")
        print("   - HTMLãƒ•ã‚¡ã‚¤ãƒ«: ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã„ã¦ãƒšãƒ¼ã‚¸å†…å®¹ã‚’ç¢ºèªã§ãã¾ã™")
        print("   - JSONãƒ•ã‚¡ã‚¤ãƒ«: æ¡ˆä»¶ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ãŒæ§‹é€ åŒ–ã•ã‚Œã¦ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™")  
        print("   - CSVãƒ•ã‚¡ã‚¤ãƒ«: Excelã‚„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã§é–‹ã„ã¦åˆ†æã§ãã¾ã™")
        print("=" * 60)
    
    def run(self):
        """è‡ªå‹•å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰"""
        if OUTPUT_CONFIG["console_output"]:
            print("CrowdWorks ã‚«ãƒ†ã‚´ãƒªãƒ™ãƒ¼ã‚¹æ¡ˆä»¶æ¢ç´¢ã‚·ã‚¹ãƒ†ãƒ ")
            print("=" * 60)
        
        # ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã‚’èª­ã¿è¾¼ã¿
        categories = self.load_categories()
        if not categories:
            return
        
        try:
            # LLMã«ã‚ˆã‚‹ã‚«ãƒ†ã‚´ãƒªé¸æŠ
            selected_categories = self.select_categories_by_llm(categories, self.user_profile)
            
            if not selected_categories:
                if OUTPUT_CONFIG["console_output"]:
                    print("âš ï¸  é©åˆ‡ãªã‚«ãƒ†ã‚´ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                return
            
            # å…¨ã‚«ãƒ†ã‚´ãƒªã®æ¡ˆä»¶ã‚’åé›†
            all_jobs = []
            all_matches = []
            
            # é¸æŠã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã§ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ
            for i, selected_category in enumerate(selected_categories, 1):
                if OUTPUT_CONFIG["console_output"]:
                    print(f"\nğŸ¯ å®Ÿè¡Œ {i}/{len(selected_categories)}: {selected_category['name']}")
                
                # ã‚«ãƒ†ã‚´ãƒªãƒšãƒ¼ã‚¸ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
                html_files = self.scrape_category_jobs(selected_category['url'])
                if not html_files:
                    continue
                
                # æ¡ˆä»¶æŠ½å‡ºï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã¯è¡Œã‚ãªã„ï¼‰
                category_jobs = self.extract_jobs_only(html_files)
                all_jobs.extend(category_jobs)
                
                # ãƒãƒƒãƒãƒ³ã‚°è©•ä¾¡ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã¯è¡Œã‚ãªã„ï¼‰
                category_matches = self.match_jobs_only(category_jobs)
                all_matches.extend(category_matches)
                
                # çµæœè¡¨ç¤º
                self.display_matches(category_matches)
                
                # é€£ç¶šå®Ÿè¡Œã®å ´åˆã¯å¾…æ©Ÿ
                if i < len(selected_categories):
                    delay = EXECUTION_CONFIG.get("delay_between_categories", 5)
                    if OUTPUT_CONFIG["console_output"]:
                        print(f"\nâ³ æ¬¡ã®ã‚«ãƒ†ã‚´ãƒªã¾ã§ {delay} ç§’å¾…æ©Ÿ...")
                    time.sleep(delay)
            
            # å…¨ã‚«ãƒ†ã‚´ãƒªã®æ¡ˆä»¶ã‚’çµ±åˆã—ã¦ä¿å­˜
            if all_jobs:
                self.save_all_jobs_and_matches(all_jobs, all_matches)
        
        except KeyboardInterrupt:
            if OUTPUT_CONFIG["console_output"]:
                print("\n\nâš ï¸  ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
        
        finally:
            # ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±ã‚’è¡¨ç¤º
            self.display_saved_files_summary()
            if OUTPUT_CONFIG["console_output"]:
                print("\nãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼")

    def select_categories_by_llm(self, categories: Dict, user_profile: UserProfile) -> List[Dict]:
        """LLMã‚’ä½¿ç”¨ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã«åŸºã¥ã„ã¦æœ€é©ãªã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ"""
        if not LLM_CATEGORY_SELECTION_CONFIG["enabled"]:
            if OUTPUT_CONFIG["console_output"]:
                print("âš ï¸  LLMã‚«ãƒ†ã‚´ãƒªé¸æŠãŒç„¡åŠ¹ã«ãªã£ã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚«ãƒ†ã‚´ãƒªã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return self._get_default_categories(categories)
        
        if OUTPUT_CONFIG["console_output"]:
            print("ğŸ¤– LLMã«ã‚ˆã‚‹ã‚«ãƒ†ã‚´ãƒªé¸æŠã‚’å®Ÿè¡Œä¸­...")


        main_categories = categories['main_categories']
        categories_and_url = {}
        for main_category in main_categories:
            subcategories = main_category['subcategories']
            for subcategory in subcategories:
                categories_and_url[subcategory['name']] = subcategory['url']

        categories_name = categories_and_url.keys()
        
        # LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
        prompt = self._create_category_selection_prompt(categories_name, user_profile)
        
        # LLMã«ã‚«ãƒ†ã‚´ãƒªé¸æŠã‚’ä¾é ¼
        response = generate_chat_completion(
            client=self.job_matcher.client,
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯CrowdWorksã®æ¡ˆä»¶ã‚«ãƒ†ã‚´ãƒªé¸æŠã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¹ã‚­ãƒ«ã€çµŒé¨“ã€å¸Œæœ›ã«åŸºã¥ã„ã¦æœ€é©ãªã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=LLM_CATEGORY_SELECTION_CONFIG["temperature"]
        )

        # LLMã®å¿œç­”ã‚’è§£æ
        if hasattr(response, "choices"):
            # OpenAI/DeepSeek
            content = response.choices[0].message.content
        else:
            # Ollama
            content = response['choices'][0]['message']['content']

        selected_data = self._parse_llm_category_response(content, categories_and_url)
        

        if OUTPUT_CONFIG["console_output"]:
            print(f"âœ… LLMãŒ {len(selected_data)} å€‹ã®ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠã—ã¾ã—ãŸ")
            for i, cat in enumerate(selected_data, 1):
                print(f"   {i}. {cat['name']} ")
        
        return selected_data
    
    
    def _create_category_selection_prompt(self, categories: Dict, user_profile: UserProfile) -> str:
        """ã‚«ãƒ†ã‚´ãƒªé¸æŠç”¨ã®LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ"""
        
        prompt = f"""
ã‚ãªãŸã¯CrowdWorksã®æ¡ˆä»¶ã‚«ãƒ†ã‚´ãƒªé¸æŠã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã€æœ€ã‚‚é©ã—ãŸã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚

## ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
- **ã‚¹ã‚­ãƒ«**: {', '.join(user_profile.skills)}
- **å¸Œæœ›ã‚«ãƒ†ã‚´ãƒª**: {', '.join(user_profile.preferred_categories)}
- **è‡ªå·±ç´¹ä»‹**: {user_profile.description}

## åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ†ã‚´ãƒª
{categories}

## é¸æŠæ¡ä»¶
1. **ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¹ã‚­ãƒ«ã¨çµŒé¨“ã«æœ€ã‚‚é©ã—ãŸã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ**
2. **æœ€å¤§{LLM_CATEGORY_SELECTION_CONFIG["max_categories"]}å€‹ã®ã‚«ãƒ†ã‚´ãƒªã¾ã§é¸æŠå¯èƒ½**
3. **å„ã‚«ãƒ†ã‚´ãƒªã«0-10ã®é–¢é€£åº¦ã‚¹ã‚³ã‚¢ã‚’ä»˜ä¸**
4. **é–¢é€£åº¦ã‚¹ã‚³ã‚¢{LLM_CATEGORY_SELECTION_CONFIG["min_relevance_score"]}ä»¥ä¸Šã®ã‚«ãƒ†ã‚´ãƒªã®ã¿é¸æŠ**

## é¸æŠã®å„ªå…ˆé †ä½
1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¹ã‚­ãƒ«ã¨ç›´æ¥é–¢é€£ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’å„ªå…ˆ
2. å¸Œæœ›ã‚«ãƒ†ã‚´ãƒªã«å«ã¾ã‚Œã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’å„ªå…ˆ

## å›ç­”å½¢å¼
ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
```json
[
  {{
    "main_category": "ã‚«ãƒ†ã‚´ãƒªåï¼ˆä¸Šè¨˜ãƒªã‚¹ãƒˆã‹ã‚‰æ­£ç¢ºã«é¸æŠï¼‰",
    "relevance_score": 8.5,
  }}
]
```

**é‡è¦**: ã‚«ãƒ†ã‚´ãƒªåã¯ä¸Šè¨˜ã®ã€Œåˆ©ç”¨å¯èƒ½ãªã‚«ãƒ†ã‚´ãƒªã€ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹æ­£ç¢ºãªåå‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
"""
        return prompt
    

    def _parse_llm_category_response(self, response_text: str, categories_and_url: Dict) -> List[Dict]:
        """LLMã®å¿œç­”ã‚’è§£æã—ã¦ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã‚’æŠ½å‡º"""
        # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
        import re
        import json
        
        # JSONéƒ¨åˆ†ã‚’æ¤œç´¢
        json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
        if not json_match:
            # JSONãƒ–ãƒ­ãƒƒã‚¯ãŒãªã„å ´åˆã¯å…¨ä½“ã‚’JSONã¨ã—ã¦è§£æ
            json_text = response_text.strip()
        else:
            json_text = json_match.group(1).strip()

        # JSONãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆtrailing commaã‚’é™¤å»ï¼‰
        json_text = re.sub(r',\s*}', '}', json_text)
        json_text = re.sub(r',\s*]', ']', json_text)
        
        # JSONã‚’è§£æ
        selected_data = json.loads(json_text)
        
        # ãƒ•ãƒ©ãƒƒãƒˆãªã‚«ãƒ†ã‚´ãƒªãƒªã‚¹ãƒˆã‚’ä½œæˆï¼ˆæ¤œç´¢ç”¨ï¼‰
        flat_categories = []
        for category in selected_data:
            category_name = category['main_category']
            category_url = categories_and_url.get(category_name)
            # ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªã‚’è¿½åŠ 
            flat_categories.append({
                "name": category_name,
                "url": category_url,
            })

        return flat_categories
    


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    explorer = CrowdWorksCategoryExplorer()
    explorer.run()

if __name__ == "__main__":
    main() 